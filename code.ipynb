{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1491,
   "metadata": {},
   "outputs": [],
   "source": [
    "stai_scores = np.array(pd.read_csv(r'stai_scores.csv', header=None)[0])\n",
    "inst_choices = np.array(pd.read_csv(r'inst_choices.csv', header=None))\n",
    "inst_outcomes = np.array(pd.read_csv(r'inst_outcomes.csv', header=None))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1492,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data: mean, median, standard deviation of STAI\n",
    "overall_mean = np.mean(stai_scores)\n",
    "overall_std = np.std(stai_scores)\n",
    "overall_median = np.median(stai_scores)\n",
    "\n",
    "anxious_mean = np.mean(stai_scores[0:24])\n",
    "anxious_std = np.std(stai_scores[0:24])\n",
    "anxious_median = np.median(stai_scores[0:24])\n",
    "\n",
    "control_mean = np.mean(stai_scores[25:])\n",
    "control_std = np.std(stai_scores[25:])\n",
    "control_median = np.median(stai_scores[25:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1493,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data: cut-off = 43, ANXIOUS group if STAI>43\n",
    "cut_off_stai = np.zeros(len(stai_scores))\n",
    "for i in range(len(stai_scores)):\n",
    "    if stai_scores[i] <= 43:\n",
    "        # cut_off_stai = 1 if the subject is in the healthy control group\n",
    "        cut_off_stai[i] = 1\n",
    "\n",
    "healthy_num = sum(cut_off_stai)\n",
    "healthy_index = np.where(cut_off_stai==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring the data: number of times each subject choosing stimuli A\n",
    "chose_a_count = []\n",
    "chose_a_percent = []\n",
    "for i in range(len(inst_choices)):\n",
    "    chose_a_count.append(np.array(np.where(inst_choices[i]==1)).size)\n",
    "    chose_a_percent.append(chose_a_count[-1]/len(inst_choices[i]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value of a chosen stimuli i at time t\n",
    "# the probability of each stimulus to lead to the aversive noise, 70/30, 80/20, 60/40, 65/35\n",
    "prob_list = [[0.3,0.7],[0.2,0.8],[0.4,0.6],[0.35,0.65]]\n",
    "\n",
    "def gen_outcome(a):\n",
    "    array = []\n",
    "    for i in range(4):\n",
    "        next = np.random.choice([0, 1], size=40, p=a[i])\n",
    "        array = np.concatenate((array,next))\n",
    "    return array\n",
    "\n",
    "def stimuli_value(V0, a, outcome):\n",
    "    value = np.zeros(len(outcome.T))\n",
    "    value[0] = V0\n",
    "    for i in range(2,len(outcome.T)):\n",
    "        value[i] = value[i-1] + a*(outcome[i-1]-value[i-1])\n",
    "    return value\n",
    "\n",
    "def softmax(b, va, vb):\n",
    "    prob = np.zeros(len(va))\n",
    "    for i in range(len(va)):\n",
    "        prob[i] = round(np.exp(-b*va[i])/(np.exp(-b*va[i])+np.exp(-b*vb[i])))\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.0"
      ]
     },
     "execution_count": 1496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulation: for a single individual\n",
    "outcome_a = gen_outcome(prob_list)\n",
    "outcome_b = 1 - outcome_a\n",
    "value_a = stimuli_value(0.5,0.4,outcome_a)\n",
    "value_b = stimuli_value(0.5,0.4,outcome_b)\n",
    "choice = softmax(7,value_a,value_b)\n",
    "result = np.sum(outcome_a[np.where(choice==1)])+np.sum(outcome_b[np.where(choice==0)])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.732"
      ]
     },
     "execution_count": 1497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulation: validation with k individuals\n",
    "k = 500\n",
    "sim_mat_a = np.zeros((k,160))\n",
    "val_mat_a = np.zeros((k,160))\n",
    "val_mat_b = np.zeros((k,160))\n",
    "choice_mat = np.zeros((k,160))\n",
    "for i in range(k):\n",
    "    sim_mat_a[i] = gen_outcome(prob_list)\n",
    "sim_mat_b = 1 - sim_mat_a\n",
    "for i in range(k):\n",
    "    val_mat_a[i] = stimuli_value(0.5,0.4,sim_mat_a[i])\n",
    "    val_mat_b[i] = stimuli_value(0.5,0.4,sim_mat_b[i])\n",
    "    choice_mat[i] = softmax(7,val_mat_a[i],val_mat_b[i])\n",
    "\n",
    "aversive = np.zeros(k)\n",
    "for i in range(k):\n",
    "    aversive[i]=np.sum(sim_mat_a[i,np.where(choice_mat[i]==1)])+np.sum(sim_mat_b[i,np.where(choice_mat[i]==0)])\n",
    "np.mean(aversive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
